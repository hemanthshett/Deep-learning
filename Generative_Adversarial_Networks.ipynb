{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3bZOF9RQW1N"
      },
      "outputs": [],
      "source": [
        "# Import relevant libraries\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set display options; this step is optional\n",
        "\n",
        "\n",
        "torch.set_printoptions(precision=2, sci_mode=None)\n",
        "np.set_printoptions(precision=2, suppress=None)\n",
        "# Device configuration; set this to GPU for faster training\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "qDxKVU8qQiTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the tranformations to be applied on the dataset\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "  transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Download the MNIST dataset;\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./mnist_data/', train=False, transform=transform, download=True)"
      ],
      "metadata": {
        "id": "uJgEhdiNQksa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the batch size for creating train and test loaders\n",
        "\n",
        "bs = 100\n",
        "\n",
        "# Create the DataLoader class\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=True)"
      ],
      "metadata": {
        "id": "XwuWzw-BQuH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Generator network\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, g_input_dim, g_output_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.fc1 = nn.Linear(g_input_dim, 256)\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features*2)\n",
        "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features*2)\n",
        "        self.fc4 = nn.Linear(self.fc3.out_features, g_output_dim)\n",
        "\n",
        "    # forward method\n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "        return torch.tanh(self.fc4(x))\n",
        "\n",
        "# Create the Discriminator network\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, d_input_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.fc1 = nn.Linear(d_input_dim, 1024)\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features//2)\n",
        "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features//2)\n",
        "        self.fc4 = nn.Linear(self.fc3.out_features, 1)\n",
        "\n",
        "    # forward method\n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        return torch.sigmoid(self.fc4(x))  # this is a constant\n"
      ],
      "metadata": {
        "id": "gyOiBp25QuxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the GAN network by combining the Generator and Discriminator networks\n",
        "\n",
        "# Set the dimensions of the noise vector z\n",
        "z_dim = 100\n",
        "\n",
        "# Compute the input dimensions of the input vectors fed to the Discriminator\n",
        "mnist_dim = train_dataset.train_data.size(1) * train_dataset.train_data.size(2)\n",
        "\n",
        "# Initialize the Generator and Discriminator networks\n",
        "\n",
        "G = Generator(g_input_dim = z_dim, g_output_dim = mnist_dim).to(device)\n",
        "D = Discriminator(mnist_dim).to(device)"
      ],
      "metadata": {
        "id": "orIlp7drQyiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the model summary\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "print(\"Generator Network Architecture: \\n\\n\", G, \"\\n\\n\")\n",
        "print(\"Summary(Generator): \\n\", summary(G, (z_dim,)))\n",
        "\n",
        "# Visualize the discriminator network\n",
        "\n",
        "print(\"Discriminator Network Architecture: \\n\\n\", D, \"\\n\\n\")\n",
        "print(\"Summary(Generator): \\n\", summary(G, (mnist_dim, bs)))\n",
        "\n",
        "# Define the loss function to be minimized\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Initialize the optimizers for the generator and the discriminator; since requirements of the two networks are different, different optimizers are preferred\n",
        "\n",
        "lr_g = 0.002\n",
        "lr_d = 0.0002\n",
        "G_optimizer = optim.Adam(G.parameters(), lr = lr_g)\n",
        "D_optimizer = optim.Adam(D.parameters(), lr = lr_d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaMhgwwIQ2CU",
        "outputId": "e78aab77-ceb2-4ff3-fc4e-f2417d91a8d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator Network Architecture: \n",
            "\n",
            " Generator(\n",
            "  (fc1): Linear(in_features=100, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
            "  (fc3): Linear(in_features=512, out_features=1024, bias=True)\n",
            "  (fc4): Linear(in_features=1024, out_features=784, bias=True)\n",
            ") \n",
            "\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 256]          25,856\n",
            "            Linear-2                  [-1, 512]         131,584\n",
            "            Linear-3                 [-1, 1024]         525,312\n",
            "            Linear-4                  [-1, 784]         803,600\n",
            "================================================================\n",
            "Total params: 1,486,352\n",
            "Trainable params: 1,486,352\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.02\n",
            "Params size (MB): 5.67\n",
            "Estimated Total Size (MB): 5.69\n",
            "----------------------------------------------------------------\n",
            "Summary(Generator): \n",
            " None\n",
            "Discriminator Network Architecture: \n",
            "\n",
            " Discriminator(\n",
            "  (fc1): Linear(in_features=784, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (fc4): Linear(in_features=256, out_features=1, bias=True)\n",
            ") \n",
            "\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1             [-1, 784, 256]          25,856\n",
            "            Linear-2             [-1, 784, 512]         131,584\n",
            "            Linear-3            [-1, 784, 1024]         525,312\n",
            "            Linear-4             [-1, 784, 784]         803,600\n",
            "================================================================\n",
            "Total params: 1,486,352\n",
            "Trainable params: 1,486,352\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.30\n",
            "Forward/backward pass size (MB): 15.41\n",
            "Params size (MB): 5.67\n",
            "Estimated Total Size (MB): 21.38\n",
            "----------------------------------------------------------------\n",
            "Summary(Generator): \n",
            " None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the training of the Discriminator network\n",
        "\n",
        "def D_train(x):\n",
        "    #=======================Train the discriminator=======================#\n",
        "    D.zero_grad()\n",
        "\n",
        "    # train discriminator on real\n",
        "    x_real, y_real = x.view(-1, mnist_dim), torch.ones(bs, 1)\n",
        "    x_real, y_real = Variable(x_real.to(device)), Variable(y_real.to(device))\n",
        "\n",
        "    D_output = D(x_real)\n",
        "    D_real_loss = criterion(D_output, y_real)\n",
        "    D_real_score = D_output\n",
        "\n",
        "    # train discriminator on fake\n",
        "    z = Variable(torch.randn(bs, z_dim).to(device))\n",
        "    x_fake, y_fake = G(z), Variable(torch.zeros(bs, 1).to(device))\n",
        "\n",
        "    D_output = D(x_fake)\n",
        "    D_fake_loss = criterion(D_output, y_fake)\n",
        "    D_fake_score = D_output\n",
        "\n",
        "    # gradient backprop & optimize ONLY D's parameters\n",
        "    D_loss = D_real_loss + D_fake_loss\n",
        "    D_loss.backward()\n",
        "    D_optimizer.step()\n",
        "\n",
        "    return  D_loss.data.item()\n",
        "\n",
        "# Define the training of the Generator network\n",
        "\n",
        "def G_train(x):\n",
        "    #=======================Train the generator=======================#\n",
        "    G.zero_grad()\n",
        "\n",
        "    z = Variable(torch.randn(bs, z_dim).to(device))\n",
        "    y = Variable(torch.ones(bs, 1).to(device))\n",
        "\n",
        "    G_output = G(z)\n",
        "    D_output = D(G_output)\n",
        "    G_loss = criterion(D_output, y)\n",
        "\n",
        "    # gradient backprop & optimize ONLY G's parameters\n",
        "    G_loss.backward()\n",
        "    G_optimizer.step()\n",
        "\n",
        "    return G_loss.data.item()\n"
      ],
      "metadata": {
        "id": "IsU6zkQuQ-tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the GAN network\n",
        "\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "num_epochs=2\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "        D_optimizer.zero_grad()\n",
        "        real_data = data[0].to(device)\n",
        "        real_data = real_data.resize(bs, real_data.size()[2]*real_data.size()[3])\n",
        "        b_size = real_data.size(0)\n",
        "        label = torch.ones((b_size,), device=device)\n",
        "\n",
        "        output = D(real_data).view(-1)\n",
        "        errD_real = criterion(output, label)\n",
        "        errD_real.backward()\n",
        "\n",
        "        noise = torch.randn(b_size, z_dim, device=device)\n",
        "        print(\"noise.size()\", noise.size(), \"\\n\")\n",
        "        fake = G(noise)\n",
        "        label.fill_(0)\n",
        "        output = D(fake.detach()).view(-1)\n",
        "        errD_fake = criterion(output, label)\n",
        "        errD_fake.backward()\n",
        "\n",
        "        errD = errD_real + errD_fake\n",
        "        D_optimizer.step()\n",
        "\n",
        "        # Update the generator network\n",
        "        G_optimizer.zero_grad()\n",
        "        label.fill_(1)\n",
        "        output = D(fake).view(-1)\n",
        "        errG = criterion(output, label)\n",
        "        errG.backward()\n",
        "        G_optimizer.step()\n",
        "\n",
        "        # Print statistics\n",
        "        if i % 2 == 0:\n",
        "            print(\"Epoch: \", (epoch+1), \"\\tError(D): \", errD.item(), \"\\tError(G): \", errG.item(), \"\\n\")\n",
        "\n",
        "end_time = time.time()\n",
        "total_training_time = end_time - start_time\n",
        "print(\"Total training time: \\t\", (total_training_time/60), \" minutes\")"
      ],
      "metadata": {
        "id": "nBPkpawqQ_SG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}